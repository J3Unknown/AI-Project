{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df0e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart.csv') #create the data frame and read data from csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7fa5d6",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d700ac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chol'] = pd.to_numeric(df['chol'],errors='coerce') #convert non numerical values to NaN to be dropped\n",
    "df.dropna(inplace=True,how='any')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652720e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True) #drop any duplicates\n",
    "\n",
    "#print the description after removing the duplicates and transposes the matrix to show all columns\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the X and Y values for the target\n",
    "xTarget = df.drop('target',axis=1)\n",
    "yTarget = df['target']\n",
    "\n",
    "#split the data into train data and test data\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xTarget, yTarget, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df717d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values and duplicates from TRAINING data\n",
    "xtrain_clean = xtrain.dropna(how='any')\n",
    "xtrain_clean = xtrain_clean.drop_duplicates()\n",
    "\n",
    "xtest_clean = xtest.dropna(how='any')\n",
    "xtest_clean = xtest_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9db622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the IQR to remove outliers\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "\n",
    "# Clip outliers in TRAINING data\n",
    "xtest_clean = xtest_clean.clip(lower=lower_bound, upper=upper_bound, axis=1)\n",
    "\n",
    "\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31c3191",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d148fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Z-scores for all numerical columns\n",
    "numeric_cols = xtrain_clean.select_dtypes(include=['number']).columns\n",
    "numeric_cols = [col for col in numeric_cols if col != 'target']  # Exclude 'target'\n",
    "z_scores = xtrain_clean[numeric_cols].apply(lambda x: np.abs((x - x.mean()) / x.std()))\n",
    "mean_z_scores = z_scores.mean().sort_values(ascending=False)\n",
    "\n",
    "# Display Z-scores for each column\n",
    "print(\"Z-scores for each column:\")\n",
    "print(mean_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3311e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(mean_z_scores)\n",
    "high_priority = mean_z_scores[:n_features//3].index.tolist()\n",
    "medium_priority = mean_z_scores[n_features//3 : 2*(n_features//3)].index.tolist()\n",
    "low_priority = mean_z_scores[2*(n_features//3):].index.tolist()\n",
    "\n",
    "print(high_priority)\n",
    "print(medium_priority)\n",
    "print(low_priority)\n",
    "low_priority_to_drop = [col for col in low_priority if col in xtrain_clean.columns]\n",
    "xtrain_selected = xtrain_clean.drop(low_priority_to_drop, axis=1)\n",
    "xtest_selected = xtest_clean.drop(low_priority_to_drop, axis=1)\n",
    "\n",
    "features = high_priority + medium_priority\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585157df",
   "metadata": {},
   "source": [
    "#                      Scalling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139321fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the data into ranges between 0 and 1 used for KNN and SVM\n",
    "minMaxScaler = MinMaxScaler()\n",
    "\n",
    "#fitting the High Priority Data\n",
    "xTrain_highmd = minMaxScaler.fit_transform(xtrain_selected)\n",
    "xTest_highmd = minMaxScaler.transform(xtest_selected)\n",
    "\n",
    "#converting the fitted data into data frames to be easier for tracking\n",
    "xTrain_df = pd.DataFrame(xTrain_highmd,columns=features,index=xtrain.index)\n",
    "xTest_df = pd.DataFrame(xTest_highmd, columns=features, index=xtest.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05beae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to convert data into Z-Score values to be used in logistic regression and decision tree\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#fitting the High Priority Data\n",
    "X_train_highmed= scaler.fit_transform(xtrain_selected)\n",
    "X_test_highmed = scaler.transform(xtest_selected)\n",
    "\n",
    "#recreating the data into data frames to be easier for tracking\n",
    "x_train_scaled = pd.DataFrame(X_train_highmed, columns=features, index=xtrain.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_highmed, columns=features, index=xtest.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e04cec",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb5e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyshared",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
